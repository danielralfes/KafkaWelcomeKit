# Trabalhando com Tópicos

---
A criação de um tópico pode ser tão simples como dar um nome ao mesmo e criá-lo, entretanto várias questões podem impactar diretamente a experiência final em produção.
As configurações mais importantes são número de partições e retenção de mensagem.
É possível configurar no broker o padrão de criação de todos os tópicos, ou definir individualmente.

## Particionamento

Particionamento é a forma com que o Kafka consegue escalar. Ao dividir um tópico em N partições, conseguimos realizar leitura em paralelismo.
Geralmente o número de partições será igual à quantidade de brokers no cluster.

Por padrão (parâmetro [num.partitions](https://kafka.apache.org/documentation/#brokerconfigs)), o Kafka cria tópicos com uma partição. É possível aumentar após criado, mas vale notar que uma vez aumentado, o número de partições não pode ser reduzido.

### Como escolher o número de partições?

Alguns fatores devem ser considerados ao decidir o número de partições:

#### Considerar o throughput esperado para o tópico, por exemplo 1GB/seg

Lembrar-se da teoria das restrições. No Kafka, a fim de garantir ordem de entrega das mensagens, temos no máximo 1 consumer por partition dentro de um mesmo consumer group, logo, se seu consumer tem um throughput máximo de 100MB/segundo, então o processamento máximo alcançado pelo seu tópico será de 100mb/segundo.
É importante fazer essa análise para não superestimar seu particionamento, uma vez que eles aumentam a necessidade de memória e disco no broker Kafka.

Num contexto de mensageria básica, throughput pode não ser algo tão relevante, mas se lembrarmos que o objetivo inicial do Kafka é real time streaming, lidamos com alto throughput.

Vamos fazer um exerício simples: Suponhamos que você tenha um fluxo de entrada esperado de 1GB/seg em um tópico, e sabe que cada consumer tem a capacidade máxima de processar 100MB/seg, então podemos chegar a conclusão de que serão necessários 10 consumers para atingir o throughput esperado. Como dito anteriormente, apenas 1 consumer é utilizado por partição, ou seja, o tópico precisaria ter 20 partições para trabalhar com 20 consumers.

Se você não dispor de informações detalhadas da volumetria esperada, é recomendado que o tamanho da partição em disco não seja maior que 6 gb por dia de retenção.

Além disso, quanto maior o número de consumer groups, maior o impacto em performance no broker dada a necessidade de replicação de mensagens e garantia de ordem para todos os grupos.

#### Consumer group

Ao definir um consumer group, indicamos ao Kafka que queremos separar o consumo em contexto. Cada consumer group possui um controle de offset a parte, navegando de forma independente no log.

![log_consumer.png](arquivos/log_consumer-7683d42b-29c2-438d-bc44-ef1b3788943d.png)
[Fonte: [Kafka Documentation](https://kafka.apache.org/documentation/#intro_topics)]

É importante salientar que caso haja apenas um consumer group com vários consumers, haverá balancemento de carga entre eles, e o broker entregará as mensagens da forma de um barramento de mensageria tradicional (queue based).
Caso hajam distintos consumer groups, trabalhamos então em um modelo de subscription (pub-sub based), onde o broker realiza broadcast da mensagem para todos os consumer groups.

## Rentenção

Existem duas formas de configurar retenção de mensagens no Kafka, por tempo de vida ou por limite de armazenamento.

É possível configurar ambos os triggers de expurgo, sendo este realizado por quem disparar primeiro. Ou seja, se o parametro [log.retention.hours](https://kafka.apache.org/documentation/#brokerconfigs) for definido como 24, e o parâmetro [log.retention.bytes](https://kafka.apache.org/documentation/#brokerconfigs) for definido como 1000000000 (1 GB), é possível que mensagens sejam expurgadas em menos de 24 horas caso no dia tenham sido recebidos mais de 1GB de mensagens.

Atenção ao fato de que o Kafka não é um mecanismo de enfileiramento de mensagens, mas um mecanismo pub-sub. É importante destacar que ele trabalha com um conceito de log, ou seja, todas as mensagens recebidas ficam disponíveis para consumo por um tempo determinado (por padrão 7 dias). Caso um consumer fique fora do ar por período maior que o TTL (time to live) da mensagem, ele perderá a mesma. O mesmo vale para a política de expurgo por limite de armazenamento.

### Garantia de ordenação

O Kafka somente garantirá ordenação se você tiver um producer enviando mensagens para uma partição e um consumer lendo mensagens de uma partição. As mensagens são preservadas em ordem no log da partição conforme elas chegam, então não é possível garantir ordenação se múltiplos producers enviam simultaneamente numa mesma partição.

## Melhores Práticas

* Nome do tópico
Ao nomear um tópico, não é recomendado iniciar o seu nome com __ (dois underscores), pois tópicos internos do cluster utilizam este padrão.
Além disso, não é recomendado utilizar juntos "." e "_" nos nomes, pois para gerar métricas o Kafka transforma . para _

* Número de Partições
Aumentamos o paralelismo adicionando mais consumers, então pode ser necessário aumentar o número de partições em um tópico existente, contudo, caso na criação do tópico tenha sido utilizada alguma estratégia de particionamento por chave (keyed messages), não é recomendado aumentar o número de partições posteriormente, pois causará resizing no topic.
Importante: Caso seja necessário reduzir a quantidade de partições em um tópico, é necessário excluir o tópico e recriá-lo.

* Chaves
Quando produzimos uma mensagem, caso não seja informada a Key do registro e exista mais de uma partição, o Kafka utilizará um algorítmo round-robin para balancear entre as partições existentes. Se for informada a Key na produção da mensagem, esta cairá sempre na mesma partição, a ser determinada pela hash da key.
Pode existir cenários onde a frequência de uma key seja maior que as demais, isso resultará em uma partição muito grande, já que além de receber todas mensagens dessa key, receberá também  mensagens de outras keys através do balanceamento. Para evitar esse cenário, é possível construir um custom [partitioner](https://kafka.apache.org/10/javadoc/org/apache/kafka/clients/producer/Partitioner.html) com alguma regra de segregação específica.

* Garantia de entrega ordenada
Existem casos de uso onde a ordem de recebimento das mensagens é crítica. Imagine um cenário onde o cliente deposita R$ 100,00 e em seguida saca R$ 100,00. Se a ordem de recebimento das mensagens não for mantida pode-se gerar um grande problema.
Nestes cenários, pode ser interessante configurar o parâmetro [max.in.flights.requests.per.session = 1](https://docs.confluent.io/current/installation/configuration/producer-configs.html). Por padrão ele vem configurado com o valor 5, significando que o broker receberá até 5 mensagens em lote para processar, e neste caso havendo problema ao realizar commit da primeira mensagem no broker e sucesso na segunda, ao tentar novamente a primeira, as mensagens invertem a ordem.
Note que realizar essa configuração para aceitar requests de apenas uma mensagem por vez significa diminuir o throughput do producer, logo deve ser usada apenas nestes cenários.
